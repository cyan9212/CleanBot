{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"electra_base.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"85829a299ea94a058143924735870e33":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_01950098199842d7957b8b2b5861a527","IPY_MODEL_5fd79bda5a0043bda53cf7921937bbbb","IPY_MODEL_6e14a08cf2704198807a0c442bae1dfe"],"layout":"IPY_MODEL_573dc7e8621d47b980c7e694c36203d6"}},"01950098199842d7957b8b2b5861a527":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8dcb48c26e44fc5a69df65d8999edb2","placeholder":"​","style":"IPY_MODEL_b033212e2b1249158c25a92dd3b4a39d","value":"  6%"}},"5fd79bda5a0043bda53cf7921937bbbb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_9805bb1e80184bb2a2b2d4a59ede93ca","max":300,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7c1e1a110468460f98313866a9632385","value":19}},"6e14a08cf2704198807a0c442bae1dfe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ca87fbcc9b9457cae1c84045cd59cec","placeholder":"​","style":"IPY_MODEL_9a593211a9e441e4b68f5924121ba422","value":" 19/300 [29:21&lt;6:49:33, 87.45s/it]"}},"573dc7e8621d47b980c7e694c36203d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8dcb48c26e44fc5a69df65d8999edb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b033212e2b1249158c25a92dd3b4a39d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9805bb1e80184bb2a2b2d4a59ede93ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c1e1a110468460f98313866a9632385":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ca87fbcc9b9457cae1c84045cd59cec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a593211a9e441e4b68f5924121ba422":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"765aa72040b4438ab77743b7f35dfaca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_522b9cbcb6f748e68e34f70ba0a50662","IPY_MODEL_b7a827ba3683437d84c411d9e6cf2c08","IPY_MODEL_d4a37a729f264b1e9319ecf654a1e4d5"],"layout":"IPY_MODEL_5b25a96031cc460fad042edffbd3ac89"}},"522b9cbcb6f748e68e34f70ba0a50662":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12d8e4afbbe247a3aed3d4af7fddb117","placeholder":"​","style":"IPY_MODEL_3638db5805e44393a8032ddef03ac5f2","value":"100%"}},"b7a827ba3683437d84c411d9e6cf2c08":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_44bbef9747484273b1ef82b0bbb4d3fb","max":46,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1c6ab006e9f845519affb1f8cf82a1a7","value":46}},"d4a37a729f264b1e9319ecf654a1e4d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df8e6b535dca4016abe7e7ff38e94c50","placeholder":"​","style":"IPY_MODEL_5058a25ca70f44a3b6f9aa00651e2241","value":" 46/46 [00:09&lt;00:00,  4.67it/s]"}},"5b25a96031cc460fad042edffbd3ac89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12d8e4afbbe247a3aed3d4af7fddb117":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3638db5805e44393a8032ddef03ac5f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"44bbef9747484273b1ef82b0bbb4d3fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c6ab006e9f845519affb1f8cf82a1a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"df8e6b535dca4016abe7e7ff38e94c50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5058a25ca70f44a3b6f9aa00651e2241":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lB8Amt__y2jn","outputId":"624d5764-348c-4910-d53c-95bbc4cbb0e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from tqdm.notebook import tqdm\n","%matplotlib inline"],"metadata":{"id":"xigNtkrqy5dc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings(action='ignore')"],"metadata":{"id":"FfQ9LR_bBEvT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JIVfTlUXzDuM","outputId":"39208f5f-b7a6-4078-8cee-919fb80e94f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 5.5 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 46.5 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 6.7 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 49.2 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 35.0 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.18.0\n"]}]},{"cell_type":"code","source":["from transformers import ElectraModel, ElectraTokenizerFast\n","from transformers import ElectraForSequenceClassification, AdamW\n","from transformers import get_cosine_schedule_with_warmup\n","\n","\n","tokenizer = ElectraTokenizerFast.from_pretrained(\"kykim/electra-kor-base\")"],"metadata":{"id":"h-hwPhx2zFgr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PATH = '/content/gdrive/MyDrive/Colab Notebooks/project/'\n","cate = '성별'\n","df = pd.read_csv(PATH + f'{cate}.csv')"],"metadata":{"id":"7pOOjAYTzLE-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = df[['문장', f'{cate}']]"],"metadata":{"id":"oKqINu1OzLhH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset, TensorDataset, DataLoader, random_split\n","from torch import torch\n","from sklearn.model_selection import train_test_split\n","\n","def dataSplit(dataset, y_label):\n","  X_train, X_val= train_test_split(dataset, test_size = 0.2, stratify = dataset[y_label], random_state =427)\n","  return X_train, X_val"],"metadata":{"id":"VuECARvZzOGQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = dataSplit(df, cate)\n","\n","# validation 추가\n","X_train, X_val = dataSplit(X_train, cate)"],"metadata":{"id":"cqt-BG5OzRzj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class LoadDataset(Dataset):\n","    def __init__(self, df, tk):\n","        self.df = df\n","        self.tokenizer = tk\n","\n","    def __len__(self):\n","        return len(self.df)\n","  \n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx, :].values\n","        # target이 없는경우 (즉, 문장만 입력된 경우)\n","        if len(row) <= 1:\n","            text = row[0]\n","\n","            inputs = self.tokenizer(\n","                text, \n","                return_tensors='pt',\n","                truncation=True,\n","                max_length=50,\n","                pad_to_max_length=True,\n","                add_special_tokens=True\n","                )\n","            \n","            input_ids = inputs['input_ids'][0]\n","            attention_mask = inputs['attention_mask'][0]\n","\n","            return input_ids, attention_mask     \n","            \n","        # target이 있는 경우 (원래 코드)\n","        else:\n","            text = row[0]\n","            y = row[1]\n","\n","            inputs = self.tokenizer(\n","                text, \n","                return_tensors='pt',\n","                truncation=True,\n","                max_length=50,\n","                pad_to_max_length=True,\n","                add_special_tokens=True\n","                )\n","            \n","            input_ids = inputs['input_ids'][0]\n","            attention_mask = inputs['attention_mask'][0]\n","\n","            return input_ids, attention_mask, y"],"metadata":{"id":"aQF11tKUzZLO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_set = LoadDataset(X_train, tokenizer)\n","val_set = LoadDataset(X_val, tokenizer)\n","test_set = LoadDataset(X_test, tokenizer)"],"metadata":{"id":"H7fu_ZOdzcLY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = ElectraForSequenceClassification.from_pretrained('kykim/electra-kor-base')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6N9zpLDM3fAO","outputId":"0063399b-0264-4bff-89cd-1aef9db66388"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at kykim/electra-kor-base were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at kykim/electra-kor-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["model.classifier.out_proj =  nn.Sequential( nn.Linear(768, 1),\n","                                           nn.Sigmoid() )\n","\n","# model.classifier.out_proj = nn.Linear(256, 1) # model 변경"],"metadata":{"id":"lawzElr9BAzy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\")\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z9tISRc_9aEU","outputId":"c07965c8-e140-4e85-f825-4e19993619bc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ElectraForSequenceClassification(\n","  (electra): ElectraModel(\n","    (embeddings): ElectraEmbeddings(\n","      (word_embeddings): Embedding(42000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): ElectraEncoder(\n","      (layer): ModuleList(\n","        (0): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): ElectraClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Sequential(\n","      (0): Linear(in_features=768, out_features=1, bias=True)\n","      (1): Sigmoid()\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["epochs = 300 # epochs 증가\n","batch_size = 32\n","warmup_ratio=0.1\n","t_total = len(train_set) * epochs\n","optimizer = AdamW(model.parameters(), lr=1e-5, eps = 1e-8) # lr 1/10으로 변경\n","train_loader = DataLoader(train_set, batch_size=batch_size)\n","val_loader = DataLoader(val_set, batch_size=batch_size) # val loader 추가\n","test_loader = DataLoader(test_set, batch_size = batch_size) # test loader 추가\n","loss_f = nn.BCEWithLogitsLoss() # loss f 변경\n","\n","scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=1, num_training_steps=t_total)"],"metadata":{"id":"lja3veMazd6x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://github.com/Bjarten/early-stopping-pytorch\n","class EarlyStopping:\n","    def __init__(self, patience=7, verbose=False, delta=0, path=f'/content/gdrive/MyDrive/checkpoint_{cate}.pt'):\n","        \"\"\"\n","        Args:\n","            patience (int): validation loss가 개선된 후 기다리는 기간\n","                            Default: 7\n","            verbose (bool): True일 경우 각 validation loss의 개선 사항 메세지 출력\n","                            Default: False\n","            delta (float): 개선되었다고 인정되는 monitered quantity의 최소 변화\n","                            Default: 0\n","            path (str): checkpoint저장 경로\n","                            Default: 'checkpoint.pt'\n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"],"metadata":{"id":"kHlPCOHivsmO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["early_stopping = EarlyStopping(patience = 7, verbose = True)"],"metadata":{"id":"n64GeVPd10LX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import roc_auc_score\n","\n","for i in tqdm(range(epochs)):\n","    train_loss_list = [] # 변수 변경\n","    val_loss_list = []\n","    val_score_list = []\n","\n","    epoch_train_loss = []\n","    epoch_val_loss = []\n","    epoch_val_score = []\n","    # train\n","    model.train()\n","    for input_ids_batch, attention_masks_batch, y_batch in train_loader:\n","        input_ids_batch = input_ids_batch.to(device)\n","        attention_masks_batch = attention_masks_batch.to(device)\n","        y_batch = y_batch.to(device)\n","        optimizer.zero_grad()\n","        y_pred = model(input_ids_batch, attention_mask=attention_masks_batch).logits.reshape(-1)\n","        loss = loss_f(y_pred.type(torch.FloatTensor), y_batch.type(torch.FloatTensor))\n","\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        train_loss_list.append(loss.item())\n","\n","    # validation loss\n","    model.eval()\n","    for input_ids_batch_val, attention_masks_batch_val, y_batch_val in val_loader:\n","        input_ids_batch_val = input_ids_batch_val.to(device)\n","        attention_masks_batch_val = attention_masks_batch_val.to(device)\n","        y_batch_val = y_batch_val.to(device)\n","        y_pred_val = model(input_ids_batch_val, attention_mask = attention_masks_batch_val).logits.reshape(-1)\n","        loss = loss_f(y_pred_val.type(torch.FloatTensor), y_batch_val.type(torch.FloatTensor))\n","        val_score = roc_auc_score(y_batch_val.tolist(), y_pred_val.tolist())\n","        val_loss_list.append(loss.item())\n","        val_score_list.append(val_score)\n","\n","    # epoch당 loss 계산 (for early stopping)\n","    train_loss = np.average(train_loss_list)\n","    val_loss = np.average(val_loss_list)\n","    val_score = np.average(val_score_list)\n","\n","    epoch_train_loss.append(train_loss)\n","    epoch_val_loss.append(val_loss)\n","    epoch_val_score.append(val_score)\n","    epoch_len = len(str(epochs))\n","\n","    print_msg = (f'[{i:>{epoch_len}}/{epochs:>{epoch_len}}] ' +\n","                 f'train_loss: {train_loss:.5f} ' +\n","                 f'valid_loss: {val_loss:.5f} ' +\n","                 f'valid_score: {val_score:.5f}')\n","\n","    print(print_msg)\n","    \n","    # clear lists to track next epoch\n","    train_loss_list = []\n","    val_loss_list = []\n","    val_score_list = []\n","    early_stopping(val_loss, model)\n","    if early_stopping.early_stop:\n","        print('early stopping')\n","        break\n","    \n","model.load_state_dict(torch.load(f'/content/gdrive/MyDrive/checkpoint_{cate}.pt', map_location=device))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":820,"referenced_widgets":["85829a299ea94a058143924735870e33","01950098199842d7957b8b2b5861a527","5fd79bda5a0043bda53cf7921937bbbb","6e14a08cf2704198807a0c442bae1dfe","573dc7e8621d47b980c7e694c36203d6","c8dcb48c26e44fc5a69df65d8999edb2","b033212e2b1249158c25a92dd3b4a39d","9805bb1e80184bb2a2b2d4a59ede93ca","7c1e1a110468460f98313866a9632385","0ca87fbcc9b9457cae1c84045cd59cec","9a593211a9e441e4b68f5924121ba422"]},"id":"O7rM5PxbzfKx","outputId":"82701754-244e-40f7-8d2b-291247bcdd09"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/300 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85829a299ea94a058143924735870e33"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[  0/300] train_loss: 0.69468 valid_loss: 0.65087 valid_score: 0.82331\n","Validation loss decreased (inf --> 0.650871).  Saving model ...\n","[  1/300] train_loss: 0.59539 valid_loss: 0.55226 valid_score: 0.94316\n","Validation loss decreased (0.650871 --> 0.552261).  Saving model ...\n","[  2/300] train_loss: 0.55268 valid_loss: 0.54622 valid_score: 0.95376\n","Validation loss decreased (0.552261 --> 0.546225).  Saving model ...\n","[  3/300] train_loss: 0.54523 valid_loss: 0.54628 valid_score: 0.94974\n","EarlyStopping counter: 1 out of 7\n","[  4/300] train_loss: 0.53896 valid_loss: 0.54229 valid_score: 0.95647\n","Validation loss decreased (0.546225 --> 0.542290).  Saving model ...\n","[  5/300] train_loss: 0.53254 valid_loss: 0.54134 valid_score: 0.95397\n","Validation loss decreased (0.542290 --> 0.541340).  Saving model ...\n","[  6/300] train_loss: 0.53226 valid_loss: 0.54211 valid_score: 0.94861\n","EarlyStopping counter: 1 out of 7\n","[  7/300] train_loss: 0.53153 valid_loss: 0.54408 valid_score: 0.96136\n","EarlyStopping counter: 2 out of 7\n","[  8/300] train_loss: 0.52912 valid_loss: 0.54104 valid_score: 0.95576\n","Validation loss decreased (0.541340 --> 0.541036).  Saving model ...\n","[  9/300] train_loss: 0.52679 valid_loss: 0.54034 valid_score: 0.95692\n","Validation loss decreased (0.541036 --> 0.540337).  Saving model ...\n","[ 10/300] train_loss: 0.52661 valid_loss: 0.54636 valid_score: 0.96198\n","EarlyStopping counter: 1 out of 7\n","[ 11/300] train_loss: 0.52382 valid_loss: 0.54586 valid_score: 0.96282\n","EarlyStopping counter: 2 out of 7\n","[ 12/300] train_loss: 0.52258 valid_loss: 0.53918 valid_score: 0.96173\n","Validation loss decreased (0.540337 --> 0.539184).  Saving model ...\n","[ 13/300] train_loss: 0.52412 valid_loss: 0.54798 valid_score: 0.96248\n","EarlyStopping counter: 1 out of 7\n","[ 14/300] train_loss: 0.52317 valid_loss: 0.53986 valid_score: 0.96408\n","EarlyStopping counter: 2 out of 7\n","[ 15/300] train_loss: 0.52346 valid_loss: 0.54464 valid_score: 0.96598\n","EarlyStopping counter: 3 out of 7\n","[ 16/300] train_loss: 0.52314 valid_loss: 0.54067 valid_score: 0.95965\n","EarlyStopping counter: 4 out of 7\n","[ 17/300] train_loss: 0.52223 valid_loss: 0.54005 valid_score: 0.95257\n","EarlyStopping counter: 5 out of 7\n","[ 18/300] train_loss: 0.52261 valid_loss: 0.54418 valid_score: 0.95501\n","EarlyStopping counter: 6 out of 7\n","[ 19/300] train_loss: 0.52347 valid_loss: 0.54531 valid_score: 0.94268\n","EarlyStopping counter: 7 out of 7\n","early stopping\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":["model.eval()\n","score_list = []\n","for input_ids_batch, attention_masks_batch, y_batch in tqdm(test_loader):\n","    input_ids_batch = input_ids_batch.to(device)\n","    attention_masks_batch = attention_masks_batch.to(device)\n","    y_batch = y_batch.to(device)\n","    y_pred = model(input_ids_batch, attention_mask=attention_masks_batch).logits.reshape(-1)\n","#    print(y_pred)\n","    try:\n","        score = roc_auc_score(y_batch.tolist(), y_pred.tolist())\n","        score_list.append(score)\n","    except: pass\n","\n","\n","print(\"epoch roc_auc:\", np.mean(score_list))"],"metadata":{"id":"WxzEU2hzziIb","colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["765aa72040b4438ab77743b7f35dfaca","522b9cbcb6f748e68e34f70ba0a50662","b7a827ba3683437d84c411d9e6cf2c08","d4a37a729f264b1e9319ecf654a1e4d5","5b25a96031cc460fad042edffbd3ac89","12d8e4afbbe247a3aed3d4af7fddb117","3638db5805e44393a8032ddef03ac5f2","44bbef9747484273b1ef82b0bbb4d3fb","1c6ab006e9f845519affb1f8cf82a1a7","df8e6b535dca4016abe7e7ff38e94c50","5058a25ca70f44a3b6f9aa00651e2241"]},"outputId":"d1415a94-4906-4e56-ae50-06b027dc7c32"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/46 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"765aa72040b4438ab77743b7f35dfaca"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["epoch roc_auc: 0.9608960960686461\n"]}]},{"cell_type":"code","source":["# score 기록하기\n","final_score = np.mean(score_list)"],"metadata":{"id":"ZsFyggj1MCH4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#korean_col_name_list = ['clean','local','religion_model','']\n","#eng_model_name_list = ['clean','지역','종교','인종국적','연령','악플욕설','성소수자','성별','기타혐오','개인지칭']\n","\n","#translate_dict = {}\n","\n","torch.save(model.state_dict(), PATH + f'{cate}.pth')"],"metadata":{"id":"fTZT49953_Kc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(final_score, cate)"],"metadata":{"id":"HN3PQbl4qrCg","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d5b8f3d7-5c46-4139-c682-abaf1e46ec75"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9608960960686461 성별\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"j6tEx-HZM6Ne"},"execution_count":null,"outputs":[]}]}